这里是softmax算子的实现

计算过程：
    1、先求出最大值
    2、每一个数值减去最大值，防止计算exp时候出现上溢，并求出exp后的sum
    3、每一个数计算exp的值再除去sum，然后写回

对于GPU版本的实现思路：
v1：
    1. 使用shared memory
    2. 一个block处理一行，dim block(32,1)  x方向32个，y方向1个（其实我也在想改成比较大的比如（96，1），这样可以隐藏延迟）
    3. 块内规约，见v1.png
    4. 对于从global->shared mmeory，就用向量化取值来减少访存次数
    5. 注意，只是为了实现这个softmax，所以数据设置的比较少，并没有要去适配好多形状的矩阵